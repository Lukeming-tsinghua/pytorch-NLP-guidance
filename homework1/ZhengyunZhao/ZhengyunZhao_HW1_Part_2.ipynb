{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data/', train = True, \n",
    "                            transform = transforms.Compose(\n",
    "                                [transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.131],[0.308])]))\n",
    "test_data = datasets.MNIST(root = './data/', train = False, \n",
    "                          transform = transforms.Compose(\n",
    "                                [transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.133],[0.309])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                         batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H_1, H_2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.Linear1 = nn.Linear(D_in, H_1)\n",
    "        self.Linear2 = nn.Linear(H_1, H_2)\n",
    "        self.Linear3 = nn.Linear(H_2, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_1 = F.relu(self.Linear1(x))\n",
    "        h_2 = F.relu(self.Linear2(h_1))\n",
    "        y_pred = self.Linear3(h_2)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(784, 196, 49, 10)\n",
    "if torch.cuda.is_available() == True:\n",
    "    model = model.cuda()\n",
    "crit = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_id, (data, y) in enumerate(train_loader):\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        if torch.cuda.is_available() == True:\n",
    "            data = data.cuda()\n",
    "            y = y.cuda()\n",
    "        y_pred = model(data)\n",
    "        loss = crit(y_pred, y)\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, Loss:{}'.format(epoch, batch_id, loss.item()))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    accuracy = 0\n",
    "    for idx, (data, y) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available() == True:\n",
    "            data = data.cuda()\n",
    "            y = y.cuda()\n",
    "        prob = model(data.view(data.shape[0], -1))\n",
    "        y_pred = prob.max(1, keepdim = True)[1]\n",
    "        accuracy += y_pred.eq(y.view_as(y_pred)).sum()\n",
    "    print (accuracy.item() / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss:2.3138883113861084\n",
      "Epoch: 0, Batch: 100, Loss:2.020395040512085\n",
      "Epoch: 0, Batch: 200, Loss:1.1703168153762817\n",
      "Epoch: 0, Batch: 300, Loss:0.7072461247444153\n",
      "Epoch: 0, Batch: 400, Loss:0.6283529996871948\n",
      "Epoch: 0, Batch: 500, Loss:0.5561915040016174\n",
      "Epoch: 0, Batch: 600, Loss:0.49006593227386475\n",
      "Epoch: 0, Batch: 700, Loss:0.46359163522720337\n",
      "Epoch: 0, Batch: 800, Loss:0.2847071588039398\n",
      "Epoch: 0, Batch: 900, Loss:0.3571622669696808\n",
      "Epoch: 1, Batch: 0, Loss:0.36635226011276245\n",
      "Epoch: 1, Batch: 100, Loss:0.3533521294593811\n",
      "Epoch: 1, Batch: 200, Loss:0.4699513912200928\n",
      "Epoch: 1, Batch: 300, Loss:0.4315120577812195\n",
      "Epoch: 1, Batch: 400, Loss:0.5315122008323669\n",
      "Epoch: 1, Batch: 500, Loss:0.41508474946022034\n",
      "Epoch: 1, Batch: 600, Loss:0.36075714230537415\n",
      "Epoch: 1, Batch: 700, Loss:0.16152268648147583\n",
      "Epoch: 1, Batch: 800, Loss:0.2698308527469635\n",
      "Epoch: 1, Batch: 900, Loss:0.2778359055519104\n",
      "Epoch: 2, Batch: 0, Loss:0.21237421035766602\n",
      "Epoch: 2, Batch: 100, Loss:0.2567371726036072\n",
      "Epoch: 2, Batch: 200, Loss:0.37956592440605164\n",
      "Epoch: 2, Batch: 300, Loss:0.27269795536994934\n",
      "Epoch: 2, Batch: 400, Loss:0.26157620549201965\n",
      "Epoch: 2, Batch: 500, Loss:0.13803762197494507\n",
      "Epoch: 2, Batch: 600, Loss:0.283817321062088\n",
      "Epoch: 2, Batch: 700, Loss:0.11283983290195465\n",
      "Epoch: 2, Batch: 800, Loss:0.2784888446331024\n",
      "Epoch: 2, Batch: 900, Loss:0.24647800624370575\n",
      "Epoch: 3, Batch: 0, Loss:0.22221916913986206\n",
      "Epoch: 3, Batch: 100, Loss:0.4551454782485962\n",
      "Epoch: 3, Batch: 200, Loss:0.15619394183158875\n",
      "Epoch: 3, Batch: 300, Loss:0.25768759846687317\n",
      "Epoch: 3, Batch: 400, Loss:0.10975570231676102\n",
      "Epoch: 3, Batch: 500, Loss:0.1411810666322708\n",
      "Epoch: 3, Batch: 600, Loss:0.2796836793422699\n",
      "Epoch: 3, Batch: 700, Loss:0.3456815481185913\n",
      "Epoch: 3, Batch: 800, Loss:0.22660310566425323\n",
      "Epoch: 3, Batch: 900, Loss:0.20218026638031006\n",
      "Epoch: 4, Batch: 0, Loss:0.36552631855010986\n",
      "Epoch: 4, Batch: 100, Loss:0.07866604626178741\n",
      "Epoch: 4, Batch: 200, Loss:0.3831225037574768\n",
      "Epoch: 4, Batch: 300, Loss:0.1397019326686859\n",
      "Epoch: 4, Batch: 400, Loss:0.144607275724411\n",
      "Epoch: 4, Batch: 500, Loss:0.1773887276649475\n",
      "Epoch: 4, Batch: 600, Loss:0.30216583609580994\n",
      "Epoch: 4, Batch: 700, Loss:0.1087213084101677\n",
      "Epoch: 4, Batch: 800, Loss:0.3021641969680786\n",
      "Epoch: 4, Batch: 900, Loss:0.14654791355133057\n",
      "Epoch: 5, Batch: 0, Loss:0.14528074860572815\n",
      "Epoch: 5, Batch: 100, Loss:0.1445614993572235\n",
      "Epoch: 5, Batch: 200, Loss:0.2941542863845825\n",
      "Epoch: 5, Batch: 300, Loss:0.15327011048793793\n",
      "Epoch: 5, Batch: 400, Loss:0.08284241706132889\n",
      "Epoch: 5, Batch: 500, Loss:0.17292115092277527\n",
      "Epoch: 5, Batch: 600, Loss:0.08736023306846619\n",
      "Epoch: 5, Batch: 700, Loss:0.15172138810157776\n",
      "Epoch: 5, Batch: 800, Loss:0.16736716032028198\n",
      "Epoch: 5, Batch: 900, Loss:0.33108019828796387\n",
      "Epoch: 6, Batch: 0, Loss:0.254891037940979\n",
      "Epoch: 6, Batch: 100, Loss:0.14861711859703064\n",
      "Epoch: 6, Batch: 200, Loss:0.1426106095314026\n",
      "Epoch: 6, Batch: 300, Loss:0.0717964619398117\n",
      "Epoch: 6, Batch: 400, Loss:0.07713759690523148\n",
      "Epoch: 6, Batch: 500, Loss:0.11359009891748428\n",
      "Epoch: 6, Batch: 600, Loss:0.22441422939300537\n",
      "Epoch: 6, Batch: 700, Loss:0.07122685015201569\n",
      "Epoch: 6, Batch: 800, Loss:0.05461426079273224\n",
      "Epoch: 6, Batch: 900, Loss:0.05705984681844711\n",
      "Epoch: 7, Batch: 0, Loss:0.19103087484836578\n",
      "Epoch: 7, Batch: 100, Loss:0.160801500082016\n",
      "Epoch: 7, Batch: 200, Loss:0.040290094912052155\n",
      "Epoch: 7, Batch: 300, Loss:0.08124644309282303\n",
      "Epoch: 7, Batch: 400, Loss:0.2451106309890747\n",
      "Epoch: 7, Batch: 500, Loss:0.10837189853191376\n",
      "Epoch: 7, Batch: 600, Loss:0.04695303365588188\n",
      "Epoch: 7, Batch: 700, Loss:0.20860162377357483\n",
      "Epoch: 7, Batch: 800, Loss:0.06669065356254578\n",
      "Epoch: 7, Batch: 900, Loss:0.20092995464801788\n",
      "Epoch: 8, Batch: 0, Loss:0.1313861459493637\n",
      "Epoch: 8, Batch: 100, Loss:0.24826598167419434\n",
      "Epoch: 8, Batch: 200, Loss:0.08163730800151825\n",
      "Epoch: 8, Batch: 300, Loss:0.10534463077783585\n",
      "Epoch: 8, Batch: 400, Loss:0.0770142674446106\n",
      "Epoch: 8, Batch: 500, Loss:0.04763796180486679\n",
      "Epoch: 8, Batch: 600, Loss:0.09488406777381897\n",
      "Epoch: 8, Batch: 700, Loss:0.22033189237117767\n",
      "Epoch: 8, Batch: 800, Loss:0.1662960946559906\n",
      "Epoch: 8, Batch: 900, Loss:0.10441003739833832\n",
      "Epoch: 9, Batch: 0, Loss:0.03715657442808151\n",
      "Epoch: 9, Batch: 100, Loss:0.07135073840618134\n",
      "Epoch: 9, Batch: 200, Loss:0.05930924043059349\n",
      "Epoch: 9, Batch: 300, Loss:0.09572901576757431\n",
      "Epoch: 9, Batch: 400, Loss:0.15801285207271576\n",
      "Epoch: 9, Batch: 500, Loss:0.08924808353185654\n",
      "Epoch: 9, Batch: 600, Loss:0.18542833626270294\n",
      "Epoch: 9, Batch: 700, Loss:0.05455397069454193\n",
      "Epoch: 9, Batch: 800, Loss:0.1552526354789734\n",
      "Epoch: 9, Batch: 900, Loss:0.07007943838834763\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 10\n",
    "for i in range(NUM_EPOCH):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n"
     ]
    }
   ],
   "source": [
    "dtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
