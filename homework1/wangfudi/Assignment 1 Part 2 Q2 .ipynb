{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.02\n",
    "num_epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('./mnist/', train=True, transform = transforms.ToTensor())\n",
    "test_set = datasets.MNIST('./mnist/', train=False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden1, num_hidden2, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(input_dim, num_hidden1), nn.BatchNorm1d(num_hidden1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(num_hidden1, num_hidden2), nn.BatchNorm1d(num_hidden2), nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(num_hidden2, out_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(784, 300, 100, 10)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 50, loss: 0.2358\n",
      "Epoch: 1, Batch: 100, loss: 0.1778\n",
      "Epoch: 1, Batch: 150, loss: 0.2591\n",
      "Epoch: 1, Batch: 200, loss: 0.1789\n",
      "Epoch: 1, Batch: 250, loss: 0.1072\n",
      "Epoch: 1, Batch: 300, loss: 0.2681\n",
      "Epoch: 1, Batch: 350, loss: 0.2933\n",
      "Epoch: 1, Batch: 400, loss: 0.143\n",
      "Epoch: 1, Batch: 450, loss: 0.08315\n",
      "Epoch: 1, Batch: 500, loss: 0.08407\n",
      "Epoch: 1, Batch: 550, loss: 0.08522\n",
      "Epoch: 1, Batch: 600, loss: 0.2368\n",
      "Epoch: 1, Batch: 650, loss: 0.1772\n",
      "Epoch: 1, Batch: 700, loss: 0.17\n",
      "Epoch: 1, Batch: 750, loss: 0.1917\n",
      "Epoch: 1, Batch: 800, loss: 0.2851\n",
      "Epoch: 1, Batch: 850, loss: 0.147\n",
      "Epoch: 1, Batch: 900, loss: 0.12\n",
      "Epoch: 2, Batch: 50, loss: 0.1654\n",
      "Epoch: 2, Batch: 100, loss: 0.1956\n",
      "Epoch: 2, Batch: 150, loss: 0.3397\n",
      "Epoch: 2, Batch: 200, loss: 0.04956\n",
      "Epoch: 2, Batch: 250, loss: 0.184\n",
      "Epoch: 2, Batch: 300, loss: 0.09885\n",
      "Epoch: 2, Batch: 350, loss: 0.1653\n",
      "Epoch: 2, Batch: 400, loss: 0.2773\n",
      "Epoch: 2, Batch: 450, loss: 0.08238\n",
      "Epoch: 2, Batch: 500, loss: 0.05222\n",
      "Epoch: 2, Batch: 550, loss: 0.1418\n",
      "Epoch: 2, Batch: 600, loss: 0.09187\n",
      "Epoch: 2, Batch: 650, loss: 0.1147\n",
      "Epoch: 2, Batch: 700, loss: 0.1281\n",
      "Epoch: 2, Batch: 750, loss: 0.06721\n",
      "Epoch: 2, Batch: 800, loss: 0.2233\n",
      "Epoch: 2, Batch: 850, loss: 0.1378\n",
      "Epoch: 2, Batch: 900, loss: 0.1981\n",
      "Epoch: 3, Batch: 50, loss: 0.1482\n",
      "Epoch: 3, Batch: 100, loss: 0.07092\n",
      "Epoch: 3, Batch: 150, loss: 0.08071\n",
      "Epoch: 3, Batch: 200, loss: 0.03633\n",
      "Epoch: 3, Batch: 250, loss: 0.2504\n",
      "Epoch: 3, Batch: 300, loss: 0.08561\n",
      "Epoch: 3, Batch: 350, loss: 0.03067\n",
      "Epoch: 3, Batch: 400, loss: 0.05458\n",
      "Epoch: 3, Batch: 450, loss: 0.2796\n",
      "Epoch: 3, Batch: 500, loss: 0.05137\n",
      "Epoch: 3, Batch: 550, loss: 0.1339\n",
      "Epoch: 3, Batch: 600, loss: 0.05956\n",
      "Epoch: 3, Batch: 650, loss: 0.2104\n",
      "Epoch: 3, Batch: 700, loss: 0.0149\n",
      "Epoch: 3, Batch: 750, loss: 0.1608\n",
      "Epoch: 3, Batch: 800, loss: 0.1425\n",
      "Epoch: 3, Batch: 850, loss: 0.1729\n",
      "Epoch: 3, Batch: 900, loss: 0.09151\n",
      "Epoch: 4, Batch: 50, loss: 0.02413\n",
      "Epoch: 4, Batch: 100, loss: 0.05748\n",
      "Epoch: 4, Batch: 150, loss: 0.02455\n",
      "Epoch: 4, Batch: 200, loss: 0.03145\n",
      "Epoch: 4, Batch: 250, loss: 0.005021\n",
      "Epoch: 4, Batch: 300, loss: 0.03496\n",
      "Epoch: 4, Batch: 350, loss: 0.03238\n",
      "Epoch: 4, Batch: 400, loss: 0.02956\n",
      "Epoch: 4, Batch: 450, loss: 0.0785\n",
      "Epoch: 4, Batch: 500, loss: 0.01262\n",
      "Epoch: 4, Batch: 550, loss: 0.03888\n",
      "Epoch: 4, Batch: 600, loss: 0.1484\n",
      "Epoch: 4, Batch: 650, loss: 0.03648\n",
      "Epoch: 4, Batch: 700, loss: 0.03634\n",
      "Epoch: 4, Batch: 750, loss: 0.01878\n",
      "Epoch: 4, Batch: 800, loss: 0.02082\n",
      "Epoch: 4, Batch: 850, loss: 0.0427\n",
      "Epoch: 4, Batch: 900, loss: 0.03964\n",
      "Epoch: 5, Batch: 50, loss: 0.01187\n",
      "Epoch: 5, Batch: 100, loss: 0.04912\n",
      "Epoch: 5, Batch: 150, loss: 0.05469\n",
      "Epoch: 5, Batch: 200, loss: 0.01527\n",
      "Epoch: 5, Batch: 250, loss: 0.04673\n",
      "Epoch: 5, Batch: 300, loss: 0.01901\n",
      "Epoch: 5, Batch: 350, loss: 0.007095\n",
      "Epoch: 5, Batch: 400, loss: 0.1935\n",
      "Epoch: 5, Batch: 450, loss: 0.08804\n",
      "Epoch: 5, Batch: 500, loss: 0.02921\n",
      "Epoch: 5, Batch: 550, loss: 0.07377\n",
      "Epoch: 5, Batch: 600, loss: 0.1387\n",
      "Epoch: 5, Batch: 650, loss: 0.0452\n",
      "Epoch: 5, Batch: 700, loss: 0.2405\n",
      "Epoch: 5, Batch: 750, loss: 0.04765\n",
      "Epoch: 5, Batch: 800, loss: 0.04533\n",
      "Epoch: 5, Batch: 850, loss: 0.01404\n",
      "Epoch: 5, Batch: 900, loss: 0.03313\n",
      "Epoch: 6, Batch: 50, loss: 0.07929\n",
      "Epoch: 6, Batch: 100, loss: 0.006693\n",
      "Epoch: 6, Batch: 150, loss: 0.07043\n",
      "Epoch: 6, Batch: 200, loss: 0.1516\n",
      "Epoch: 6, Batch: 250, loss: 0.01633\n",
      "Epoch: 6, Batch: 300, loss: 0.05542\n",
      "Epoch: 6, Batch: 350, loss: 0.01279\n",
      "Epoch: 6, Batch: 400, loss: 0.06015\n",
      "Epoch: 6, Batch: 450, loss: 0.1138\n",
      "Epoch: 6, Batch: 500, loss: 0.06068\n",
      "Epoch: 6, Batch: 550, loss: 0.02658\n",
      "Epoch: 6, Batch: 600, loss: 0.03314\n",
      "Epoch: 6, Batch: 650, loss: 0.1447\n",
      "Epoch: 6, Batch: 700, loss: 0.04945\n",
      "Epoch: 6, Batch: 750, loss: 0.1148\n",
      "Epoch: 6, Batch: 800, loss: 0.007\n",
      "Epoch: 6, Batch: 850, loss: 0.0799\n",
      "Epoch: 6, Batch: 900, loss: 0.003239\n",
      "Epoch: 7, Batch: 50, loss: 0.03001\n",
      "Epoch: 7, Batch: 100, loss: 0.008861\n",
      "Epoch: 7, Batch: 150, loss: 0.005163\n",
      "Epoch: 7, Batch: 200, loss: 0.1235\n",
      "Epoch: 7, Batch: 250, loss: 0.04854\n",
      "Epoch: 7, Batch: 300, loss: 0.09597\n",
      "Epoch: 7, Batch: 350, loss: 0.01736\n",
      "Epoch: 7, Batch: 400, loss: 0.07247\n",
      "Epoch: 7, Batch: 450, loss: 0.1074\n",
      "Epoch: 7, Batch: 500, loss: 0.05185\n",
      "Epoch: 7, Batch: 550, loss: 0.02009\n",
      "Epoch: 7, Batch: 600, loss: 0.05053\n",
      "Epoch: 7, Batch: 650, loss: 0.02622\n",
      "Epoch: 7, Batch: 700, loss: 0.01549\n",
      "Epoch: 7, Batch: 750, loss: 0.1556\n",
      "Epoch: 7, Batch: 800, loss: 0.1856\n",
      "Epoch: 7, Batch: 850, loss: 0.01366\n",
      "Epoch: 7, Batch: 900, loss: 0.04081\n",
      "Epoch: 8, Batch: 50, loss: 0.04228\n",
      "Epoch: 8, Batch: 100, loss: 0.1538\n",
      "Epoch: 8, Batch: 150, loss: 0.02975\n",
      "Epoch: 8, Batch: 200, loss: 0.1064\n",
      "Epoch: 8, Batch: 250, loss: 0.1688\n",
      "Epoch: 8, Batch: 300, loss: 0.007933\n",
      "Epoch: 8, Batch: 350, loss: 0.005867\n",
      "Epoch: 8, Batch: 400, loss: 0.007329\n",
      "Epoch: 8, Batch: 450, loss: 0.002087\n",
      "Epoch: 8, Batch: 500, loss: 0.04297\n",
      "Epoch: 8, Batch: 550, loss: 0.05567\n",
      "Epoch: 8, Batch: 600, loss: 0.05011\n",
      "Epoch: 8, Batch: 650, loss: 0.03674\n",
      "Epoch: 8, Batch: 700, loss: 0.04193\n",
      "Epoch: 8, Batch: 750, loss: 0.02802\n",
      "Epoch: 8, Batch: 800, loss: 0.002722\n",
      "Epoch: 8, Batch: 850, loss: 0.02792\n",
      "Epoch: 8, Batch: 900, loss: 0.04232\n",
      "Epoch: 9, Batch: 50, loss: 0.01716\n",
      "Epoch: 9, Batch: 100, loss: 0.06543\n",
      "Epoch: 9, Batch: 150, loss: 0.07529\n",
      "Epoch: 9, Batch: 200, loss: 0.0007677\n",
      "Epoch: 9, Batch: 250, loss: 0.09566\n",
      "Epoch: 9, Batch: 300, loss: 0.1211\n",
      "Epoch: 9, Batch: 350, loss: 0.02062\n",
      "Epoch: 9, Batch: 400, loss: 0.1053\n",
      "Epoch: 9, Batch: 450, loss: 0.009039\n",
      "Epoch: 9, Batch: 500, loss: 0.01524\n",
      "Epoch: 9, Batch: 550, loss: 0.009701\n",
      "Epoch: 9, Batch: 600, loss: 0.04153\n",
      "Epoch: 9, Batch: 650, loss: 0.1212\n",
      "Epoch: 9, Batch: 700, loss: 0.00115\n",
      "Epoch: 9, Batch: 750, loss: 0.01169\n",
      "Epoch: 9, Batch: 800, loss: 0.1904\n",
      "Epoch: 9, Batch: 850, loss: 0.1387\n",
      "Epoch: 9, Batch: 900, loss: 0.00468\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "for epoch in range(num_epoches):\n",
    "    batch = 0\n",
    "    for img,label in train_loader:\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # forward \n",
    "        pred = model(img)\n",
    "        loss = criterion(pred, label)\n",
    "        print_loss = loss.data.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch += 1\n",
    "        if batch % 50 == 0:\n",
    "            print('Epoch: {}, Batch: {}, loss: {:.4}'.format(epoch, batch, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.085259, Acc: 0.976000\n"
     ]
    }
   ],
   "source": [
    "# model testing \n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "eval_acc = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    " \n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    eval_loss += loss.data.item()*label.size(0)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    eval_acc += num_correct.item()\n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(test_set)), eval_acc / (len(test_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
